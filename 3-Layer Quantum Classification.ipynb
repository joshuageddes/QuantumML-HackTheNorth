{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0c9d1f",
   "metadata": {},
   "source": [
    "# Relevant imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b654468",
   "metadata": {},
   "source": [
    "# Provided formatting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_concatenated_string(array):\n",
    "    return \",\".join(str(x) for x in array)\n",
    "\n",
    "def concatenated_string_to_array(string):\n",
    "    return np.array([int(x) for x in string.split(\",\")])\n",
    "\n",
    "def parse_input(giant_string):\n",
    "    X_train_part, Y_train_part, X_test_part = giant_string.split(\"XXX\")\n",
    "\n",
    "    X_train_row_strings = X_train_part.split(\"S\")\n",
    "    X_train_rows = [[float(x) for x in row.split(\",\")] for row in X_train_row_strings]\n",
    "    X_train = np.array(X_train_rows)\n",
    "\n",
    "    Y_train = concatenated_string_to_array(Y_train_part)\n",
    "\n",
    "    X_test_row_strings = X_test_part.split(\"S\")\n",
    "    X_test_rows = [[float(x) for x in row.split(\",\")] for row in X_test_row_strings]\n",
    "    X_test = np.array(X_test_rows)\n",
    "\n",
    "    return X_train, Y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a93a73",
   "metadata": {},
   "source": [
    "# Reading input, building train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All data read from input.txt file, one long string\n",
    "text_file = open(\"input.txt\", \"r\")\n",
    "data = text_file.read()\n",
    "text_file.close()\n",
    "X_train, Y_train, X_test = parse_input(data)\n",
    "\n",
    "#format Y_train data to One Hot encoding\n",
    "Y_train = Y_train + 1\n",
    "Y_train = tf.one_hot(Y_train, 3)\n",
    "\n",
    "#Y_test is from Challenge github. It's only neccessary for the judging demo to show accuracy\n",
    "Y_test = tf.one_hot(np.array([1,0,-1,0,-1,1,-1,-1,0,-1,1,-1,0,1,0,-1,-1,0,0,1,1,0,-1,0,0,-1,0,-1,0,0,1,1,-1,-1,-1,0,-1,0,1,0,-1,1,1,0,-1,-1,-1,-1,0,0\n",
    "])+1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c7c335",
   "metadata": {},
   "source": [
    "# Building quantum circuit (3 Qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c811f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 3\n",
    "device = qml.device(\"default.qubit\", wires=n_neurons)\n",
    "\n",
    "@qml.qnode(device)\n",
    "def qnode(inputs, weights):\n",
    "    \n",
    "    #Encode n_layers features into QuBits \n",
    "    qml.AngleEmbedding(inputs, wires=range(n_neurons))\n",
    "    \n",
    "    #One paramater rotation layer with CNOT gates on each QuBit\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_neurons))\n",
    "    \n",
    "    #Returns evaluation of PauliZ matrix on each QuBit feature\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_neurons)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b073a510",
   "metadata": {},
   "source": [
    "# Building quantum layer and Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b503eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 3\n",
    "weight_shapes = {\"weights\": (n_layers, n_neurons)}\n",
    "#Convert QNode into Keras Layer\n",
    "qlayer = qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_neurons)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(3, activation='relu'))\n",
    "model.add(qlayer)\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.09)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36163b",
   "metadata": {},
   "source": [
    "# Fitting model to trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87800193",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=2, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaeb0af",
   "metadata": {},
   "source": [
    "# Evaluating model with unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041a7fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Evaluating Model\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81692bc2",
   "metadata": {},
   "source": [
    "# Formatting test results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, verbose=0)\n",
    "output = (tf.argmax(predictions, axis=1)-1).numpy()\n",
    "output = array_to_concatenated_string(output)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
